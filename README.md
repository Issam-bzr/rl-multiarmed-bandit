# rl-multiarmed-bandit
Implements Epsilon-Greedy, UCB, and Random strategies for a multi-armed bandit problem.
